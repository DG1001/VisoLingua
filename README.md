# VisoLingua - Live Translation Overlay Tool

Ein benutzerfreundliches Desktop-Tool fÃ¼r Live-Ãœbersetzung mit transparentem Overlay-Fenster, optimiert fÃ¼r chinesische Texte.

## Screenshots

### Scan-Fenster (Capture-Modus)
![Scan Fenster](screen_scan.png)
*Transparentes Overlay-Fenster zum Erfassen von Text fÃ¼r die Ãœbersetzung*

### Ãœbersetzungsergebnis
![Ãœbersetzung](screen_translate.png)
*Ergebnis-Fenster mit der Ã¼bersetzten Text-Ausgabe*

## Features

### ğŸ¯ **Kernfunktionen**
- **Transparentes Capture-Fenster**: Verschiebbar und grÃ¶ÃŸenverstellbar Ã¼ber anderen Anwendungen
- **LLM-Integration**: UnterstÃ¼tzt Gemini 2.5 Flash und GPT-4 Mini/Nano  
- **Ein-Klick-Ãœbersetzung**: Einfach in das Overlay-Fenster klicken
- **Dual-Modus-System**: Nahtloser Wechsel zwischen Capture- und Ergebnis-Modus

### ğŸŒ **SprachunterstÃ¼tzung**
- **Chinesisch-Fokus**: Optimiert fÃ¼r vereinfachte und traditionelle chinesische Zeichen
- **Automatische Spracherkennung**: Erkennt Quellsprache automatisch
- **Mehrsprachig**: UnterstÃ¼tzt viele Sprachen â†’ Deutsch

### âš¡ **Performance & UX**
- **Intelligentes Caching**: Identische Screenshots werden nicht erneut Ã¼bersetzt
- **Verlauf**: Speicherung und Abruf der letzten Ãœbersetzungen
- **Cross-Platform**: Windows, Linux, macOS
- **DPI-Aware**: Perfekte Darstellung auf High-DPI-Displays

## ğŸš€ Quick Start

### Installation
```bash
# 1. Repository klonen oder herunterladen
# 2. Python 3.8+ installieren
# 3. Dependencies installieren
pip install -r requirements.txt
```

### Erste Einrichtung
```bash
# App starten
python main.py

# Bei erstem Start:
# 1. API-SchlÃ¼ssel in Settings eingeben
# 2. Standard-LLM auswÃ¤hlen (empfohlen: Gemini 2.5 Flash)
# 3. Fertig!
```

### API-SchlÃ¼ssel konfigurieren
- **Gemini API**: [Google AI Studio](https://aistudio.google.com/) â†’ API Key erstellen
- **OpenAI API**: [OpenAI Platform](https://platform.openai.com/) â†’ Secret Key erstellen

## ğŸ’¡ Verwendung

### Grundlegende Bedienung
1. **App starten**: `python main.py`
2. **Scan-Fenster positionieren**: Ãœber den zu Ã¼bersetzenden Text ziehen
3. **Screenshot aufnehmen**: Ins rote Overlay-Fenster klicken
4. **Ãœbersetzung erhalten**: Automatischer Wechsel zum Ergebnis-Fenster
5. **ZurÃ¼ck zum Scan**: "Back to Capture" Button oder Fenster schlieÃŸen

### Modi wechseln
- **Doppelklick** auf Overlay-Titelleiste â†’ Zum Ergebnis-Fenster
- **"Back to Capture"** Button â†’ ZurÃ¼ck zum Scan-Fenster
- **Fenster schlieÃŸen** â†’ ZurÃ¼ck zum Scan-Fenster
- **X-Button am Overlay** â†’ App beenden

### Hotkeys & Shortcuts
- `Strg+Tab`: Zwischen Modi wechseln
- `Strg+C`: Ãœbersetzung kopieren (im Ergebnis-Modus)
- `Esc`: Ergebnis-Fenster schlieÃŸen (zurÃ¼ck zu Capture)
- **Doppelklick Titelleiste**: Mode wechseln

## Projektstruktur

```
VisoLingua/
â”œâ”€â”€ main.py              # Hauptprogramm
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ settings.py      # Konfigurationsverwaltung
â”‚   â””â”€â”€ config.ini       # Benutzereinstellungen
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ overlay.py       # Transparentes Overlay
â”‚   â””â”€â”€ result_window.py # Ergebnisfenster
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ screenshot.py    # Screenshot-Erfassung
â”‚   â””â”€â”€ translator.py    # LLM-Integration
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ helpers.py       # Hilfsfunktionen
â”‚   â””â”€â”€ constants.py     # Konstanten
â””â”€â”€ requirements.txt     # Dependencies
```

## ğŸ¤– UnterstÃ¼tzte LLMs

### â˜ï¸ Cloud LLMs (API-Keys erforderlich)

| LLM | Geschwindigkeit | Kosten | QualitÃ¤t | Empfehlung |
|-----|----------------|--------|----------|------------|
| **Gemini 2.5 Flash** | âš¡âš¡âš¡ | ğŸ’° | â­â­â­â­ | âœ… **Empfohlen** |
| **GPT-4.1 Mini** | âš¡âš¡ | ğŸ’°ğŸ’° | â­â­â­â­â­ | FÃ¼r beste QualitÃ¤t |
| **GPT-4.1 Nano** | âš¡âš¡âš¡ | ğŸ’° | â­â­â­ | Experimentell |

### ğŸ  Lokale LLMs mit Ollama (100% privat, kostenlos)

| Modell | Parameter | Downloads | Performance | Chinesisch | Beschreibung |
|--------|-----------|-----------|-------------|------------|-------------|
| **gemma3** | 1b-27b | 9.4M | âš¡âš¡âš¡ | â­â­â­ | Aktuellstes Modell fÃ¼r Single-GPU |
| **qwen2.5-vl** | 3b-72b | 400K | âš¡âš¡âš¡ | â­â­â­â­â­ | Flagship Vision-Modell von Qwen |
| **llava** | 7b-34b | 7.9M | âš¡âš¡ | â­â­â­â­ | BewÃ¤hrtes Vision-Sprachmodell |
| **minicpm-v** | 8b | 2.4M | âš¡âš¡ | â­â­â­â­ | Kompaktes multimodales Modell |
| **llama3.2-vision** | 11b-90b | 2.2M | âš¡âš¡ | â­â­â­ | Meta's Vision-Modell |
| **llava-llama3** | 8b | 1.3M | âš¡âš¡ | â­â­â­â­ | LLaVA mit Llama 3 Basis |
| **llama4** | 16x17b-128x17b | 467K | âš¡ | â­â­â­ | Meta's neuestes multimodales Modell |
| **moondream** | 1.8b | 223K | âš¡âš¡âš¡ | â­â­ | Optimiert fÃ¼r Edge-GerÃ¤te |

#### Ollama Setup:
```bash
# 1. Ollama installieren (https://ollama.ai)
# 2. Modell pullen (Beispiel):
ollama pull llava:7b

# 3. In VisoLingua: Settings â†’ Local Ollama â†’ Enable
```

## ğŸ“‹ Systemanforderungen

### Minimum (Cloud LLMs)
- **Python**: 3.8+
- **Betriebssystem**: Windows 10+, Linux (GUI), macOS 10.14+
- **RAM**: 2GB verfÃ¼gbar
- **Internet**: FÃ¼r LLM-API-Calls

### Empfohlen (Cloud LLMs) 
- **Python**: 3.9+
- **RAM**: 4GB+
- **Display**: 1920x1080+ (High-DPI unterstÃ¼tzt)
- **Internet**: Stabile Breitbandverbindung

### Lokale LLMs (Ollama)
- **GPU**: NVIDIA mit 6GB+ VRAM (empfohlen) oder CPU-only
- **RAM**: 16GB+ (je nach Modell, siehe Tabelle oben)
- **Speicher**: 5-40GB fÃ¼r Modelle
- **Ollama**: Installiert und lÃ¤uft lokal

## ğŸ› ï¸ Technische Details

### Architektur
- **Frontend**: tkinter (Cross-Platform GUI)
- **Screenshot**: mss + PIL ImageGrab (Fallback)
- **LLM-APIs**: aiohttp (Async requests)
- **Threading**: Async/await fÃ¼r Non-blocking UI

### Besondere Features
- **Thread-safe Screenshot-Erfassung** mit MSS-Fallbacks
- **DPI-Awareness** fÃ¼r Windows High-DPI-Displays  
- **Intelligentes Caching** mit MD5-Hash-Vergleich
- **Robuste Fehlerbehandlung** mit mehreren Fallback-Methoden

### Inspiriert von
- [OverText](https://github.com/thiswillbeyourgithub/OverText) - Transparente Overlay-FunktionalitÃ¤t
- Entwickelt fÃ¼r defensive Sicherheitszwecke und SprachlernunterstÃ¼tzung

## âš ï¸ Wichtige Sicherheitshinweise

**VERWENDUNG AUF EIGENE GEFAHR!**

Wir kÃ¶nnen nicht garantieren, dass die Applikation fehlerfrei ist und immer nur den ausgewÃ¤hlten Scan-Bereich an das LLM sendet. Zur GewÃ¤hrleistung maximaler PrivatsphÃ¤re und Sicherheit ist im Zweifel die Verwendung eines lokalen, selbst gehosteten LLM fÃ¼r die Ãœbersetzung angeraten.

### ğŸ  Lokale LLM-Alternative (verfÃ¼gbar!)
VisoLingua unterstÃ¼tzt jetzt **Ollama** fÃ¼r vollstÃ¤ndig private Ãœbersetzungen ohne externe API-Calls. Aktivieren Sie lokale LLMs in den Einstellungen.

## ğŸ†˜ Support & Troubleshooting

### HÃ¤ufige Probleme
- **Fenster nicht sichtbar**: Transparenz in `config.ini` anpassen
- **Screenshot-Fehler**: App lÃ¤uft mit Administrator-Rechten starten
- **API-Fehler**: API-SchlÃ¼ssel und Internetverbindung prÃ¼fen
- **DPI-Probleme**: Automatisch behoben mit DPI-Awareness

AusfÃ¼hrliche LÃ¶sungen siehe: [SETUP.md](SETUP.md)

## ğŸ“„ Lizenz

Dieses Projekt dient ausschlieÃŸlich **defensiven Sicherheitszwecken** und **SprachlernunterstÃ¼tzung**.